{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN274k1CKGMosQ9FdGmIIxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mycegcpdemo/model-building/blob/main/creating_a_model_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall torch -y\n"
      ],
      "metadata": {
        "id": "FQ24h1KsGwem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torch"
      ],
      "metadata": {
        "id": "IzSipoaQHFkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raG3XEniF0e_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code. If no GPU detected defaults to cpu\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "QLCs8cS3_ied"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "MCNey2CsALHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the OS module to dig through each dir and explore its contents\n",
        "\n",
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "5oYJjz27B-LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "7Gtn7B_8CGgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir, image_path"
      ],
      "metadata": {
        "id": "4HZCIuBdC2Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize an image and use the (PIL) python image library to do so\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "random.seed(42)\n",
        "\n",
        "# Get all the image paths using pathlib.Path.glob() function to find all files ending in .jpg\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# Get a random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "print(random_image_path)\n",
        "\n",
        "# Get image class from path name\n",
        "image_class = random_image_path.parent.stem\n",
        "print(image_class)\n",
        "\n",
        "# Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "print(\"image height \", img.height, \"image width \", img.width)\n",
        "img"
      ],
      "metadata": {
        "id": "CT6vx0uEEPQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we can use our image data with PyTorch we need to:\n",
        "\n",
        "# Turn it into tensors (numerical representations of our images).\n",
        "# Turn it into a torch.utils.data.Dataset and subsequently a torch.utils.data.DataLoader, we'll call these Dataset and DataLoader for short.\n",
        "\n",
        "# Since we're working with a vision problem, we'll be looking at torchvision.datasets for our data loading functions as well as torchvision.transforms for preparing our data.\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n"
      ],
      "metadata": {
        "id": "Pb8LjqF7HZeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets transform our images into tensors so we can work with them\n",
        "# Transforms can also include: flipping images (a form of data augmentation), resizing images and so on.\n",
        "# We compose a series of transforms we want to perform using torchvision.transform.Compose()\n",
        "\n",
        "# Machine learning is all about harnessing the power of randomness and research shows that random transforms\n",
        "# (like transforms.RandAugment() and transforms.TrivialAugmentWide()) generally perform better than hand-picked transforms.\n",
        "\n",
        "#The main parameter to pay attention to in transforms.TrivialAugmentWide() is num_magnitude_bins=31.\n",
        "#It defines how much of a range an intensity value will be picked to apply a certain transform, 0 being no range and 31 being maximum range (highest chance for highest intensity).\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "   # Resize image to 64x64\n",
        "   transforms.Resize(size=(64,64)),\n",
        "   # Flip the image randomly on the horizontal, where p is the probability of a flip, 0.5 =50% chance\n",
        "   #transforms.RandomHorizontalFlip(p=0.5),\n",
        "   transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "   # turn the PIL image into a torch.Tensor\n",
        "   transforms.ToTensor()\n",
        "\n",
        "])\n",
        "\n",
        "# Create testing transform (no data augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "o3Whm-4QoYqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we will plot the images before applying the transforms and after to show the difference.\n",
        "# This function take in the image paths (list of all images), the Transform.Compose,\n",
        "# n is the number of images to pick and seed is for the random generator\n",
        "\n",
        "\n",
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths.\n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(1, 2)\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "            ax[0].axis(\"off\")\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib\n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "plot_transformed_images(image_path_list,\n",
        "                        transform=data_transform,\n",
        "                        n=3)"
      ],
      "metadata": {
        "id": "IV09c189qFjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create datasets from our train and test images by transforming and loading them into pytorch\n",
        "# OPTION_1 We will use the torchvision.datasets.ImageFolder class.\n",
        "\n",
        "# Use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "train_data_augmented = datasets.ImageFolder(\n",
        "    root=train_dir,\n",
        "    transform=data_transform,\n",
        "    target_transform=None #transform to perform on labales (if necessary)\n",
        ")\n",
        "\n",
        "test_data_simple = datasets.ImageFolder(\n",
        "    root=test_dir,\n",
        "    transform=test_transform)\n",
        "\n",
        "print(f\"Train data:\\n{train_data_augmented}\\nTest data:\\n{test_data_simple}\")\n"
      ],
      "metadata": {
        "id": "u7zwapYdrf3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get classes as a list\n",
        "class_names = train_data_augmented.classes\n",
        "print(class_names)\n",
        "\n",
        "# Get classes as a dict\n",
        "class_dict = train_data_augmented.class_to_idx\n",
        "print(class_dict)\n",
        "\n",
        "# check the lenghts of each dataset\n",
        "print(len(train_data_augmented),len(test_data_simple))\n"
      ],
      "metadata": {
        "id": "ucGPRTg20Ngl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use indexing to find samples and their target data\n",
        "img, label = train_data_augmented[0][0], train_data_augmented[0][1]\n",
        "print(f\"Image tensor:\\n{img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ],
      "metadata": {
        "id": "7jUOs0800xgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch prefers CHW(color channels, height, width) however matplotlib prefers HWC(height, width, color channels)\n",
        "\n",
        "# Rearrange the order of dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes (before and after permute)\n",
        "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14);"
      ],
      "metadata": {
        "id": "CIztzABe2_6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We got our datasets but now we need to turn them into an iterable so\n",
        "# the model can go through each one and learn the relationships betweensamples and targets (features and labels)\n",
        "\n",
        "#Turn the train and test datasets into DataLoaders\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Turn datasets into iterables\n",
        "# Set number of workers equal to your CPU count is a normal practice.\n",
        "# Find your CPU count by using os.cpu_count()\n",
        "train_dataloader = DataLoader(train_data_augmented,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              num_workers=NUM_WORKERS)\n",
        "\n",
        "# Do not usually have to shuffle test data\n",
        "test_dataloader = DataLoader(test_data_simple,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, #dont shuffle test data because you want consistent test performance\n",
        "                             num_workers=NUM_WORKERS)\n",
        "\n",
        "train_dataloader, test_dataloader\n",
        "next(iter(train_dataloader))[0].size(), next(iter(train_dataloader))[1].size()\n"
      ],
      "metadata": {
        "id": "KDLMEzR750PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch training loop steps\n",
        "Forward pass - The model goes through all of the training data once, performing its forward() function calculations (model(x_train)).\n",
        "\n",
        "Calculate the loss - The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are (loss = loss_fn(y_pred, y_train).\n",
        "\n",
        "Zero gradients - The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step (optimizer.zero_grad()).\n",
        "\n",
        "Perform backpropagation on the loss - Computes the gradient of the loss with respect for every model parameter to be updated (each parameter with requires_grad=True). This is known as backpropagation, hence \"backwards\" (loss.backward()).\n",
        "\n",
        "Step the optimizer (gradient descent) - Update the parameters with requires_grad=True with respect to the loss gradients in order to improve them (optimizer.step())."
      ],
      "metadata": {
        "id": "MkK21BxFnEJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a CNN model\n",
        "\n",
        "# The conv layers don't change the width/height of the features if you've set\n",
        "# padding equal to (kernel_size - 1) / 2. Max pooling with kernel_size = stride = 2\n",
        "# will decrease the width/height by a factor of 2 (rounded down if input shape is not even).\n",
        "# To find the in_features you take the height/width as long as the are the same (e.g 64x64)\n",
        "# and divide it by the kernel size to the power of the number of max pooling layers before the fully connected layer\n",
        "# Example from below image input is 64x64 and 2 maxpooling layers of kernel size == 2\n",
        "# gives 64/2*2 = 16x16 image which is multiply by the number of features from the last CN layer outchannel\n",
        "# https://stackoverflow.com/questions/71385657/calculating-dimensions-of-fully-connected-layer\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Linear(in_features=64*8*8, out_features=3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = x.reshape(x.size(0), -1) #flatten to a 1D tensor to be fed into the fc layer\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = SimpleCNN().to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "KF-OYWzGnZrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use torchinfo to get an idea of the shapes going through our model\n",
        "\n",
        "torchinfo is an easy way to know what shape your image is after the final CN layer before it goes into the fully connected later.\n",
        "\n",
        "Printing out our model with print(model) gives us an idea of what's going on with our model.\n",
        "\n",
        "And we can print out the shapes of our data throughout the forward() method.\n",
        "\n",
        "However, a helpful way to get information from our model is to use torchinfo.\n",
        "\n",
        "torchinfo comes with a summary() method that takes a PyTorch model as well as an input_shape and returns what happens as a tensor moves through your model.\n",
        "\n"
      ],
      "metadata": {
        "id": "HBS4kjy3wihL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchinfo if it's not available, import it if it is\n",
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    !pip install torchinfo\n",
        "    import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model, input_size=[1, 3, 64, 64]) # do a test pass through of an example input size"
      ],
      "metadata": {
        "id": "XPfuqikZv5Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate  and accumulate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metric across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "OTaKWKsT0GxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "o2p_Jedx0HAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Single call to combine Train and Test steps\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "\n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # 3. Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn)\n",
        "\n",
        "        # 4. Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # 5. Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "Vgwpc6Hlze_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 40\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_1\n",
        "model_1_results = train(model=model,\n",
        "                        train_dataloader=train_dataloader,\n",
        "                        test_dataloader=test_dataloader,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "NnJTi8gp1-2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model_0_results keys\n",
        "model_1_results.keys()"
      ],
      "metadata": {
        "id": "TjKhUWmt4AyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the loss values of the results dictionary (training and test)\n",
        "    loss = results['train_loss']\n",
        "    test_loss = results['test_loss']\n",
        "\n",
        "    # Get the accuracy values of the results dictionary (training and test)\n",
        "    accuracy = results['train_acc']\n",
        "    test_accuracy = results['test_acc']\n",
        "\n",
        "    # Figure out how many epochs there were\n",
        "    epochs = range(len(results['train_loss']))\n",
        "\n",
        "    # Setup a plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label='train_loss')\n",
        "    plt.plot(epochs, test_loss, label='test_loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend();"
      ],
      "metadata": {
        "id": "B7yUe74s46by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_1_results)"
      ],
      "metadata": {
        "id": "tyOAyuTi5a6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}